{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have already run the download subroutine (`s2s download -c <config_file.yaml>` on the terminal) and you desire to run custom processing on it\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Writing a simple processing function](#writing-a-simple-processing-function)\n",
    "- [Iterating over selected segments to execute custom code](#iterating-over-selected-segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Stream2segment has two main functions for working with downloaded data, `process` and `imap`. Both functions run custom code (a so-called *processing function* `pyfunc`) on a selection of downloaded waveform segments. `imap` yields the output of `pyfunc` for each selected segment, `process` writes the output of `pyfunc` for each selected segment in a row of a chosen tabular file (HDF or CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream2segment.process import process, imap\n",
    "# you can type help(process) or help(imap) for documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the command `s2s init` on the terminal, a fully documented Python module (`paramtable.py`) with a processing function called `main` is available. The user can edit it immediately and in two ways:\n",
    " - Produce the desired tabular output with the s2s process command (`s2s process -p paramtable.py ...`)\n",
    " - Run customized code by invoking the module as script (`python paramtable.py`), usually calling `imap` or `process` into the usual [`if __name__ == \"__main__\":` bolerplate code](https://docs.python.org/3/library/__main__.html)\n",
    "\n",
    "**In general, and especially for big data processing, these are the recommended way to process segments, as it avoids the unnecessary overhead of a Notebook**: `imap` and `process`, if run within a notebook, are not guaranteed to fully leverage multiple processors on a given machine, if required (this depends on how the Notebook handles multi processing, which is outside our control), and will not be able to show a progress bar with the % of task done and the estimated reamining time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a simple processing function\n",
    "    \n",
    "### Database URL<a href=''>\n",
    "    \n",
    "In most cases, the database where the data has been downloaded and ready needs a simple string URL. **IMPORTANT: Pay attention to save, commit or distribute code with db URL password in it**. For simplicity, a database URL is usually extracted from the download configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream2segment.process import yaml_load\n",
    "# uncomment the line below using an existing file on your OS:\n",
    "# dburl = yaml_load(download_file.yaml)['dburl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or written here following the [RFC-1738 syntax](https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls) as in this example, where we will use an example database (2 segments) provided in the same directory of this notebook and available if you run the `s2s init` command. If you have problem loading the database, check the current working directory and be sure the databse is in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The database URL should be the parameter 'dburl' of the download configuration file.\n",
    "# Here we use an example database (2 segments) provided in the same directory of this notebook:\n",
    "import os\n",
    "dburl = 'sqlite:///' + os.path.join(os.getcwd(), 'jupyter.example.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of segments\n",
    "\n",
    "The selection of suitable segments is performed by creating a `dict` mapping one or more Segment attributes to a selection expression for that attribute (for details on the segment object and its attributes, see [the segment object](https://github.com/rizac/stream2segment/wiki/the-segment-object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream2segment.process import Segment, get_segments\n",
    "from sqlalchemy.orm import load_only\n",
    "\n",
    "# create the selection dict:\n",
    "segments_selection = {\n",
    "  'has_data': 'true',\n",
    "  'maxgap_numsamples': '[-0.5, 0.5]',\n",
    "  'event_distance_deg': '[20, 90]'\n",
    "  # other optional attributes (see cheatsheet below for details):\n",
    "  # missing_data_sec: '<120'\n",
    "  # missing_data_ratio: '<0.5'\n",
    "  # id: '<300'\n",
    "  # event.time: \"(2014-01-01T00:00:00, 2014-12-31T23:59:59)\"\n",
    "  # event.latitude: \"[24, 70]\"\n",
    "  # event.longitude: \"[-11, 24]\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing function<a name='pyfunc'></a>\n",
    "\n",
    "Each segment waveform data is stored as bytes sequence in the `segment.data` attribute. However, you seldom need to access this attribute directly: `Stream2segment` defines shortcut methods to work with the relative ObsPy Objects.\n",
    "\n",
    "For instance, let's access the the ObsPy `Stream` representing the waveform data of our `segment` object fetched above (for details, see [the segment object](https://github.com/rizac/stream2segment/wiki/the-segment-object)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_processing_function(segment, config):\n",
    "    # Get ObsPy Stream object\n",
    "    stream = segment.stream()\n",
    "    # a Stream is a collection of traces, let's take the first one (copying it, see caveat below):\n",
    "    trace = stream[0].copy()\n",
    "\n",
    "    # Now let's remove the instrumental response of the segment strem\n",
    "\n",
    "    # Get ObsPy Inventory object:\n",
    "    inventory = segment.inventory()\n",
    "    # remove the response:\n",
    "    stream_remresp = stream.remove_response(inventory)\n",
    "    trace_remresp = stream_remresp[0]\n",
    "    # print('Trace data (response removed): ' + str(trace_rr.data))\n",
    "    return segment, trace, trace_remresp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Caveat</b>: The trace data has now been permanently modified. This is not due to Stream2segment but to a specific design choice of ObsPy. **In other words, `segment.stream()` from now returns `stream_remresp`** (the stream with the response removed!):\n",
    "\n",
    "Similar to `remove_response`, several other `Stream` and `Trace` methods of `ObsPy` permanently modify the underlying data (please refer to their ObsPy documentation before applying them). In all of these cases, to recover the original trace, there are two strategies:\n",
    "\n",
    "1] (<i>recommended</i>) Preserve `segment.stream()` using remove_response on a stream copy. or copying the original trace (as in the example above)\n",
    "\n",
    "2] Reload the segment stream from the database with `segment.stream(reload=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete rocessing routine with  `imap`\n",
    "\n",
    "With the database URL, the selection of segment, and our processing function, we can now iullustrate a simple usage of, e.g., `imap`. For this purpose, we simply print the segment event magnitude, and the segment trace with and without the repsonse removed in order to show in the preactice what we just discussed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment Id: 2 (event magnitude: 8.1)\n",
      "Segment trace (first three points):\n",
      "  - Counts unit (no response removed):    [-314 -280 -251]\n",
      "  - Physical units (response removed):    [ -1.42699395e-06  -1.43603990e-06  -1.42210201e-06]\n",
      "  - As returned by `segment.stream()[0]`: [ -1.42699395e-06  -1.43603990e-06  -1.42210201e-06]\n",
      "\n",
      "Segment Id: 1 (event magnitude: 8.1)\n",
      "Segment trace (first three points):\n",
      "  - Counts unit (no response removed):    [196 211  94]\n",
      "  - Physical units (response removed):    [  5.82973528e-07   5.26137453e-07   5.78937133e-07]\n",
      "  - As returned by `segment.stream()[0]`: [  5.82973528e-07   5.26137453e-07   5.78937133e-07]\n"
     ]
    }
   ],
   "source": [
    "# and now run `imap`. The function yields the output of our proceessing function (segment, trace) and the\n",
    "# segment_id\n",
    "for (segment, trace, trace_remresp), segment_id in imap(my_processing_function, dburl, segments_selection):\n",
    "    print()\n",
    "    print('Segment Id: %d (event magnitude: %.1f)' % (segment_id, segment.event.magnitude))\n",
    "    print('Segment trace (first three points):')\n",
    "    print('  - Counts unit (no response removed):    %s' % trace.data[:3])\n",
    "    print('  - Physical units (response removed):    %s' % trace_remresp.data[:3])\n",
    "    print('  - As returned by `segment.stream()[0]`: %s' % segment.stream()[0].data[:3])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over selected segments<a name='iterating_over_selected_segments'></a>\n",
    "\n",
    "If you need even more customization, a more low level approach consists of simply work iteratively on the selected segments via `get_segments`. This is basically what `imap` and `process` do under the hood with a given segments selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream2segment.process import get_session, get_segments\n",
    "segment = None\n",
    "for seg in get_segments(dburl, segments_selection):\n",
    "    # do your work here... Let's just store the first segment and exit the loop:\n",
    "    segment = seg\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_segments` opens a database session, yields selected segments and closes the session afterwards. A [database session](https://docs.sqlalchemy.org/en/13/orm/session_basics.html) is an object that establishes all conversations with the database and represents a \"holding zone\"  for all the objects which youâ€™ve loaded or associated with it during its lifespan.\n",
    "\n",
    "Closing a session is recommended after you finished your work as it releases memory on the computer and (if the db is remote) on the server, avoiding potential problems. Note that after a session is closed, all segment objects are **detached** from the database, which means we can not access anymore all of its properties, but only those previously loaded. E.g., accessing the segment related objects (e.g. the event object) outside the for loop, raises an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Parent instance <Segment at 0x15aa1c0a0> is not bound to a Session; lazy load operation of attribute 'event' cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    seg.event\n",
    "except Exception as exc:\n",
    "    print('ERROR: ' + str(exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In very specific cases where you want to keep the segments and all related objects accessible (i.e. attached to a session) also outside a `get_segments` for-loop, you can call `get_segments` with a session object instead of a db url. Just remember to close the session manually at the end of your processing routine (see at the end of this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream2segment.process import get_session, get_segments\n",
    "session = get_session(dburl)\n",
    "\n",
    "for seg in get_segments(session, segments_selection):\n",
    "    # Let's just store again the first segment and exit the loop:\n",
    "    segment = seg\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a session open, we can safely inspect the segment object. We have already seen all segments selectable attributes and some method (`stream`, `inventory`) and also related objects such as `segment.event` which are lazy loaded for performance reasons. These related Python objects are an extremely handy feature otherwise complex to achieve without a database, with waveforms and metadata stored as files on your computer. Let's inspect some related objects (these objects are loaded into memory only upon access, and therefore we need the db session to be open):\n",
    "\n",
    "\n",
    "`Event` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event\n",
      " attributes (16 of 16 loaded):\n",
      "  event_id: 20170908_0 (str, 16 characters, showing first 10 only)\n",
      "  time: 2017-09-08 04:49:21.200000 (datetime)\n",
      "  latitude: 15.02 (float)\n",
      "  longitude: -93.81 (float)\n",
      "  depth_km: 72.0 (float)\n",
      "  author: EMSC (str)\n",
      "  catalog: EMSC-RTS (str)\n",
      "  contributor: EMSC (str)\n",
      "  contributor_id: 616600 (str)\n",
      "  mag_type: mw (str)\n",
      "  magnitude: 8.1 (float)\n",
      "  mag_author: EMSC (str)\n",
      "  event_location_name: OFFSHORE C (str, 24 characters, showing first 10 only)\n",
      "  event_type: None (NoneType)\n",
      "  webservice_id: 1 (int)\n",
      "  id: 1 (int)\n",
      " related_objects (0 of 1 loaded):\n",
      "  segments\n"
     ]
    }
   ],
   "source": [
    "evt = seg.event\n",
    "print(str(evt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the event has the back-reference `segments`, which is a list of Segment objects because by design one segment is always related to one event, whereas one event generates many recordings at different stations, and thus is related to many segments. (be aware of potential memory problems when accessing huge lists of related objects. For details, see [the segment object](https://github.com/rizac/stream2segment/wiki/the-segment-object)).\n",
    "\n",
    "The same kind of \"segments relation\" holds for boith the `Station` and `Channel` objects (see below for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Station` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station\n",
      " attributes (11 of 11 loaded):\n",
      "  network: GE (str)\n",
      "  station: RUE (str)\n",
      "  latitude: 52.4759 (float)\n",
      "  longitude: 13.78 (float)\n",
      "  elevation: 40.0 (float)\n",
      "  site_name: None (NoneType)\n",
      "  start_time: 2012-03-21 10:00:00 (datetime)\n",
      "  end_time: None (NoneType)\n",
      "  inventory_xml: b'\\x1f\\x8b\\x08\\x00\\xa4\\x99\\x1b\\\\\\x02\\xff' (bytes, 44710 elements, showing first 10 only)\n",
      "  datacenter_id: 1 (int)\n",
      "  id: 2 (int)\n",
      " related_objects (0 of 3 loaded):\n",
      "  datacenter\n",
      "  channels\n",
      "  segments\n"
     ]
    }
   ],
   "source": [
    "sta = seg.station\n",
    "print(str(sta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other accessible attributes not shown above are (for a complete list see [below](#selectable_attributes)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE.RUE\n"
     ]
    }
   ],
   "source": [
    "print(sta.netsta_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Channel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel\n",
      " attributes (12 of 12 loaded):\n",
      "  location:  (str)\n",
      "  channel: BHZ (str)\n",
      "  depth: 3.0 (float)\n",
      "  azimuth: 0.0 (float)\n",
      "  dip: -90.0 (float)\n",
      "  sensor_description: GFZ:GE1993 (str, 25 characters, showing first 10 only)\n",
      "  scale: 588000000.0 (float)\n",
      "  scale_freq: 0.02 (float)\n",
      "  scale_units: M/S (str)\n",
      "  sample_rate: 20.0 (float)\n",
      "  station_id: 2 (int)\n",
      "  id: 2 (int)\n",
      " related_objects (0 of 2 loaded):\n",
      "  station\n",
      "  segments\n"
     ]
    }
   ],
   "source": [
    "cha = seg.channel\n",
    "print(str(cha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other accessible attributes not shown above are (for a complete list see [below](#selectable_attributes)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "H\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "print(cha.band_code)\n",
    "print(cha.instrument_code)\n",
    "print(cha.orientation_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caveat** When working with lists of objects, like the `query` object above, because `Stream2segment` is designed for massive downloads, it is better to load only each object id, deferring the download of all other attributes upon access: this is what `.options(load_only('id'))` above does (note that \"id\" is an attribute common to all objects types: `Segment` , `Event`, `Station`, and so on).\n",
    "\n",
    "We suggest to use the same approach for loading lists of related objects, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt = seg.event\n",
    "# load event related segments (*risk of memory overflow: low):\n",
    "segments = evt.segments.options(load_only('id')).all()\n",
    "\n",
    "cha = seg.channel\n",
    "# load channel related segments (*risk of memory overflow: medium):\n",
    "segments = cha.segments.options(load_only('id')).all()\n",
    "\n",
    "sta = seg.station\n",
    "# load station related segments (*risk of memory overflow: high):\n",
    "segments = sta.segments.options(load_only('id')).all()\n",
    "\n",
    "dct = seg.datacenter\n",
    "# load data center (e.g. IRIS) related segments (*risk of memory overflow: very high):\n",
    "segments = dct.segments.options(load_only('id')).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* The levels of risk reported are just heuristically estimated and have to be considered reliable only relative to each other (an event has almost certainly less related segments than a channel, which has almost certainly less related segments than a station, and so on)\n",
    "\n",
    "***In any case, for really memory consuming or slow tasks, consider moving the Notebook code into a custom Python module and use the command `s2s process`, which is specifically designed to better manage memory and performance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally close session\n",
    "from stream2segment.process import close_session\n",
    "close_session(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
